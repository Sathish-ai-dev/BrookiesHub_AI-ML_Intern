# ğŸ§  Englishâ€“French Neural Translation with LSTM + Attention

This project demonstrates how to build a neural machine translation system using an encoderâ€“decoder architecture with attention mechanism. It translates English sentences into French using a small parallel corpus and deep learning techniques.

## ğŸ¯ Objective

Build a sequence-to-sequence translation model using:
- Python
- Keras (TensorFlow backend)
- LSTM layers
- Attention mechanism

## ğŸ“¦ Tools & Libraries

- Python 3.8+
- TensorFlow / Keras
- NumPy, Pandas
- Scikit-learn
- Jupyter Notebook

## ğŸ“ Project Structure

english-french-translation/ â”œâ”€â”€ translation_model.ipynb # Full training and demo notebook â”œâ”€â”€ data/ â”‚ â””â”€â”€ fra.txt # Englishâ€“French sentence pairs â”œâ”€â”€ saved_model/ â”‚ â”œâ”€â”€ encoder_model.h5 â”‚ â”œâ”€â”€ decoder_model.h5 â”‚ â””â”€â”€ tokenizer.pkl â””â”€â”€ README.md

Code

## ğŸ“š Dataset

We use the [fra.txt](https://www.manythings.org/anki/fra-eng.zip) file from the Tatoeba Project, containing thousands of Englishâ€“French sentence pairs. Each line is tab-separated:
Go. Va ! Hi. Salut !

## Code

## ğŸ§ª Model Architecture

- **Encoder**: Embedding + LSTM
- **Decoder**: Embedding + LSTM
- **Attention Layer**: Computes context vectors to focus on relevant encoder outputs
- **Output Layer**: Dense softmax over French vocabulary

## ğŸš€ How to Run

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/english-french-translation.git
   cd english-french-translation
   Install dependencies

   bash
    - pip install -r requirements.txt
    - Download and extract dataset
    - Download fra-eng.zip
Extract fra.txt into the data/ folder

Run the notebook Open translation_model.ipynb in Jupyter and run all cells to:

Preprocess data

Train the model

Save encoder/decoder/tokenizer

Test translation with demo inputs

# ğŸ§  Sample Translation
python
translate("How are you?")
# Output: "Comment Ã§a va ?"
ğŸ“ˆ Training Tips
Use 10kâ€“30k sentence pairs for faster training

Tune embedding size, LSTM units, and batch size

Add dropout or regularization for better generalization

# ğŸ’¡ Outcome
Learn how deep learning handles language translation

Understand encoderâ€“decoder architecture and attention

Build a working demo of neural machine translation

# ğŸ“œ License
This project is open-source under the MIT License.

# ğŸ™Œ Acknowledgments
ManyThings.org for the dataset

TensorFlow/Keras for the deep learning framework